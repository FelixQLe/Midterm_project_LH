{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e197e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c843aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv('data/flights-2018-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed0ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights = flights.copy()\n",
    "#columns_test = [\"fl_date\",\"mkt_carrier\",\"mkt_carrier_fl_num\",\"origin\",\"dest\",\"predicted_delay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8beca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_empty_data(column):\n",
    "    \"\"\"check nan, empty list [], dict {} column with more than 40% within column\"\"\"\n",
    "    \n",
    "    if column.isnull().sum()/len(column)*100 > 40:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def drop_na(df):\n",
    "    \"\"\"drop all columns with nan or empty list value more than 40% within column, using function check_empty_data\"\"\"\n",
    "    nan_value = np.nan\n",
    "    for col in df.columns:\n",
    "        #bool_val, nul_val = check_empty_column(df[col])\n",
    "        if check_empty_data(df[col]) == True:\n",
    "            df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f5783f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_na(df_flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83b944f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fl_date', 'mkt_unique_carrier', 'branded_code_share', 'mkt_carrier',\n",
       "       'mkt_carrier_fl_num', 'op_unique_carrier', 'tail_num',\n",
       "       'op_carrier_fl_num', 'origin_airport_id', 'origin', 'origin_city_name',\n",
       "       'dest_airport_id', 'dest', 'dest_city_name', 'crs_dep_time', 'dep_time',\n",
       "       'dep_delay', 'taxi_out', 'wheels_off', 'wheels_on', 'taxi_in',\n",
       "       'crs_arr_time', 'arr_time', 'arr_delay', 'cancelled', 'diverted', 'dup',\n",
       "       'crs_elapsed_time', 'actual_elapsed_time', 'air_time', 'flights',\n",
       "       'distance', 'row_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b902312d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>...</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>diverted</th>\n",
       "      <th>dup</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>actual_elapsed_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>flights</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>5705</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8510E</td>\n",
       "      <td>5705</td>\n",
       "      <td>15304</td>\n",
       "      <td>TPA</td>\n",
       "      <td>...</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>160</td>\n",
       "      <td>153.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>988</td>\n",
       "      <td>WN</td>\n",
       "      <td>N287WN</td>\n",
       "      <td>988</td>\n",
       "      <td>13495</td>\n",
       "      <td>MSY</td>\n",
       "      <td>...</td>\n",
       "      <td>732.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>75</td>\n",
       "      <td>69.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>1236</td>\n",
       "      <td>WN</td>\n",
       "      <td>N729SW</td>\n",
       "      <td>1236</td>\n",
       "      <td>13495</td>\n",
       "      <td>MSY</td>\n",
       "      <td>...</td>\n",
       "      <td>740.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>86.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>233</td>\n",
       "      <td>WN</td>\n",
       "      <td>N958WN</td>\n",
       "      <td>233</td>\n",
       "      <td>13495</td>\n",
       "      <td>MSY</td>\n",
       "      <td>...</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>290</td>\n",
       "      <td>283.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>446</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7708E</td>\n",
       "      <td>446</td>\n",
       "      <td>13495</td>\n",
       "      <td>MSY</td>\n",
       "      <td>...</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>105</td>\n",
       "      <td>125.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14595</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>5451</td>\n",
       "      <td>WN</td>\n",
       "      <td>N914WN</td>\n",
       "      <td>5451</td>\n",
       "      <td>12953</td>\n",
       "      <td>LGA</td>\n",
       "      <td>...</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>205</td>\n",
       "      <td>165.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14596</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>2038</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7874B</td>\n",
       "      <td>2038</td>\n",
       "      <td>12953</td>\n",
       "      <td>LGA</td>\n",
       "      <td>...</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>160</td>\n",
       "      <td>165.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14597</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>3255</td>\n",
       "      <td>WN</td>\n",
       "      <td>N767SW</td>\n",
       "      <td>3255</td>\n",
       "      <td>12953</td>\n",
       "      <td>LGA</td>\n",
       "      <td>...</td>\n",
       "      <td>1453.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>215</td>\n",
       "      <td>198.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14598</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>4880</td>\n",
       "      <td>WN</td>\n",
       "      <td>N736SA</td>\n",
       "      <td>4880</td>\n",
       "      <td>12953</td>\n",
       "      <td>LGA</td>\n",
       "      <td>...</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>185</td>\n",
       "      <td>174.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14599</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>6094</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7883A</td>\n",
       "      <td>6094</td>\n",
       "      <td>12954</td>\n",
       "      <td>LGB</td>\n",
       "      <td>...</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>75</td>\n",
       "      <td>66.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14600 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fl_date mkt_unique_carrier branded_code_share mkt_carrier  \\\n",
       "0      2018-01-01                 WN                 WN          WN   \n",
       "1      2018-01-01                 WN                 WN          WN   \n",
       "2      2018-01-01                 WN                 WN          WN   \n",
       "3      2018-01-01                 WN                 WN          WN   \n",
       "4      2018-01-01                 WN                 WN          WN   \n",
       "...           ...                ...                ...         ...   \n",
       "14595  2019-12-31                 WN                 WN          WN   \n",
       "14596  2019-12-31                 WN                 WN          WN   \n",
       "14597  2019-12-31                 WN                 WN          WN   \n",
       "14598  2019-12-31                 WN                 WN          WN   \n",
       "14599  2019-12-31                 WN                 WN          WN   \n",
       "\n",
       "       mkt_carrier_fl_num op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       "0                    5705                WN   N8510E               5705   \n",
       "1                     988                WN   N287WN                988   \n",
       "2                    1236                WN   N729SW               1236   \n",
       "3                     233                WN   N958WN                233   \n",
       "4                     446                WN   N7708E                446   \n",
       "...                   ...               ...      ...                ...   \n",
       "14595                5451                WN   N914WN               5451   \n",
       "14596                2038                WN   N7874B               2038   \n",
       "14597                3255                WN   N767SW               3255   \n",
       "14598                4880                WN   N736SA               4880   \n",
       "14599                6094                WN   N7883A               6094   \n",
       "\n",
       "       origin_airport_id origin  ... arr_time  arr_delay cancelled diverted  \\\n",
       "0                  15304    TPA  ...   1831.0       21.0         0        0   \n",
       "1                  13495    MSY  ...    732.0       -8.0         0        0   \n",
       "2                  13495    MSY  ...    740.0      -15.0         0        0   \n",
       "3                  13495    MSY  ...   1829.0        9.0         0        0   \n",
       "4                  13495    MSY  ...   2013.0       23.0         0        0   \n",
       "...                  ...    ...  ...      ...        ...       ...      ...   \n",
       "14595              12953    LGA  ...   2154.0       54.0         0        0   \n",
       "14596              12953    LGA  ...   1336.0        1.0         0        0   \n",
       "14597              12953    LGA  ...   1453.0      -17.0         0        0   \n",
       "14598              12953    LGA  ...   1149.0       -1.0         0        0   \n",
       "14599              12954    LGB  ...   1529.0      -11.0         0        0   \n",
       "\n",
       "       dup  crs_elapsed_time  actual_elapsed_time  air_time  flights  distance  \n",
       "0        N               160                153.0     134.0        1      1130  \n",
       "1        N                75                 69.0      57.0        1       302  \n",
       "2        N               100                 86.0      70.0        1       551  \n",
       "3        N               290                283.0     271.0        1      1903  \n",
       "4        N               105                125.0      83.0        1       604  \n",
       "...    ...               ...                  ...       ...      ...       ...  \n",
       "14595    N               205                165.0     155.0        1      1107  \n",
       "14596    N               160                165.0     108.0        1       725  \n",
       "14597    N               215                198.0     179.0        1      1183  \n",
       "14598    N               185                174.0     158.0        1      1010  \n",
       "14599    N                75                 66.0      54.0        1       324  \n",
       "\n",
       "[14600 rows x 32 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_num, mkt_unique_carrier, branded_code_share, op_unique_carrier, tail_num, op_carrier_fl_num, origin_airport_id, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a49a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_flights.mkt_unique_carrier == df_flights.branded_code_share).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58b9d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_con = pd.read_csv('data/fuel_comsumption-2018-2019.csv')\n",
    "passengers = pd.read_csv('data/passengers-2018-2019.csv')\n",
    "weather_df = pd.read_csv('data/weather-20182019.csv')\n",
    "#weather_df = pd.read_csv('data/weather-20182019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc4b82",
   "metadata": {},
   "source": [
    "## weather data cleaning for origin and dest city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b45aa6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>condition</th>\n",
       "      <th>origin_city_condn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Light rain</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Albany, NY</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Burbank, CA</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18671</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Sacramento, CA</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18672</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18673</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18674</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Santa Ana, CA</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18675</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18676 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fl_date   origin_city_name      condition  origin_city_condn\n",
       "0      2018-01-01    New Orleans, LA         Cloudy                NaN\n",
       "1      2018-01-01        Oakland, CA  Partly cloudy                NaN\n",
       "2      2018-01-01          Tampa, FL     Light rain                NaN\n",
       "3      2018-01-01         Albany, NY  Partly cloudy                NaN\n",
       "4      2018-01-01        Burbank, CA  Partly cloudy                NaN\n",
       "...           ...                ...            ...                ...\n",
       "18671  2019-12-31     Sacramento, CA  Partly cloudy                NaN\n",
       "18672  2019-12-31  San Francisco, CA  Partly cloudy                NaN\n",
       "18673  2019-12-31       San Jose, CA  Partly cloudy                NaN\n",
       "18674  2019-12-31      Santa Ana, CA  Partly cloudy                NaN\n",
       "18675  2019-12-31          Tampa, FL          Sunny                NaN\n",
       "\n",
       "[18676 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.rename(columns={'city': 'origin_city_name', 'date': 'fl_date'}, inplace=True)\n",
    "#weather_df.head(5)\n",
    "weather_df['origin_city_condn'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b126ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_dict = {'cloundy': ['Cloudy','Overcast'],\n",
    "                  'sunny': ['Partly cloudy','Sunny'],\n",
    "                  'low_snow' : ['Freezing drizzle','Patchy snow possible', 'Patchy light snow','Light snow'],\n",
    "                  'snow': ['Light snow showers','Moderate or heavy snow with thunder','Light showers of ice pellets','Light sleet','Moderate snow','Patchy heavy snow','Patchy moderate snow','Moderate or heavy snow showers'],\n",
    "                  'low_rainny': ['Mist','Patchy light drizzle','Light drizzle','Patchy rain possible','Light rain','Patchy sleet possible','Patchy light rain'],\n",
    "                  'rainny': ['Light rain shower','Patchy freezing drizzle possible','Patchy light rain with thunder','Heavy rain at times','Light sleet showers','Moderate or heavy rain with thunder','Heavy rain','Light freezing rain','Moderate rain','Moderate or heavy rain shower','Moderate rain at times'],\n",
    "                  'harzard': ['Thundery outbreaks possible','Blowing snow','Torrential rain shower','Freezing fog','Moderate or heavy freezing rain','Ice pellets','Fog','Moderate or heavy sleet','Heavy snow', 'Blizzard']\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58657fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, conditions in condition_dict.items():\n",
    "    for condition in conditions:\n",
    "        weather_df.loc[weather_df['condition'] == condition, \"origin_city_condn\"] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "179667a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18676, 4),\n",
       "       fl_date   dest_city_name      condition origin_city_condn\n",
       " 0  2018-01-01  New Orleans, LA         Cloudy           cloundy\n",
       " 1  2018-01-01      Oakland, CA  Partly cloudy             sunny\n",
       " 2  2018-01-01        Tampa, FL     Light rain        low_rainny\n",
       " 3  2018-01-01       Albany, NY  Partly cloudy             sunny\n",
       " 4  2018-01-01      Burbank, CA  Partly cloudy             sunny)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.shape,weather_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1b3b7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14600, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_df = flights[['fl_date', 'origin_city_name']]\n",
    "origin_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c7548d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>origin_city_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Tampa, FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date origin_city_name\n",
       "0  2018-01-01        Tampa, FL\n",
       "1  2018-01-01  New Orleans, LA\n",
       "2  2018-01-01  New Orleans, LA\n",
       "3  2018-01-01  New Orleans, LA\n",
       "4  2018-01-01  New Orleans, LA"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a9c6ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.merge(df2.drop_duplicates(subset=['A']), how='left')\n",
    "origin_weather_merged = pd.merge(origin_df, weather_df.drop_duplicates(), how=\"left\", on=[\"fl_date\",\"origin_city_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "31c7364a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14600, 3),\n",
       " fl_date              0\n",
       " origin_city_name     0\n",
       " origin_city_condn    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_weather_merged.shape, origin_weather_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d14f4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_weather_merged.drop(columns='condition', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ee1e4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_weather_merged.to_csv(\"origin_weather_merged.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369ce14e",
   "metadata": {},
   "source": [
    "#### working on dest city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cbeacc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14600, 2),\n",
       "       fl_date dest_city_name\n",
       " 0  2018-01-01     Albany, NY\n",
       " 1  2018-01-01    Houston, TX\n",
       " 2  2018-01-01    Orlando, FL\n",
       " 3  2018-01-01    Oakland, CA\n",
       " 4  2018-01-01  St. Louis, MO)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_df = flights[['fl_date', 'dest_city_name']]\n",
    "dest_df.shape,dest_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7009c49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18676, 4),\n",
       "       fl_date   dest_city_name      condition dest_city_cond\n",
       " 0  2018-01-01  New Orleans, LA         Cloudy        cloundy\n",
       " 1  2018-01-01      Oakland, CA  Partly cloudy          sunny\n",
       " 2  2018-01-01        Tampa, FL     Light rain     low_rainny\n",
       " 3  2018-01-01       Albany, NY  Partly cloudy          sunny\n",
       " 4  2018-01-01      Burbank, CA  Partly cloudy          sunny)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the weather_df above just change origin to dest(extra caution when use weather_df again)\n",
    "weather_df.rename(columns={'origin_city_name': 'dest_city_name', 'origin_city_condn': 'dest_city_cond'},inplace=True)\n",
    "weather_df.shape, weather_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "276f873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge to get weather for dest city\n",
    "dest_weather_merged = pd.merge(dest_df, weather_df.drop_duplicates(), how=\"left\", on=[\"fl_date\",\"dest_city_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9a155095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14600, 4),\n",
       "       fl_date dest_city_name      condition origin_city_condn\n",
       " 0  2018-01-01     Albany, NY  Partly cloudy             sunny\n",
       " 1  2018-01-01    Houston, TX  Partly cloudy             sunny\n",
       " 2  2018-01-01    Orlando, FL     Light rain        low_rainny\n",
       " 3  2018-01-01    Oakland, CA  Partly cloudy             sunny\n",
       " 4  2018-01-01  St. Louis, MO  Partly cloudy             sunny,\n",
       " fl_date              0\n",
       " dest_city_name       0\n",
       " condition            0\n",
       " origin_city_condn    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_weather_merged.shape, dest_weather_merged.head(5), dest_weather_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8699a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_weather_merged.rename(columns={'origin_city_condn': 'dest_city_condn'},inplace=True)\n",
    "dest_weather_merged.drop(columns='condition', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b01c1869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14600, 3),\n",
       "       fl_date dest_city_name dest_city_condn\n",
       " 0  2018-01-01     Albany, NY           sunny\n",
       " 1  2018-01-01    Houston, TX           sunny\n",
       " 2  2018-01-01    Orlando, FL      low_rainny\n",
       " 3  2018-01-01    Oakland, CA           sunny\n",
       " 4  2018-01-01  St. Louis, MO           sunny)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_weather_merged.shape,dest_weather_merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d1647616",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_weather_merged.to_csv(\"dest_weather_merged.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad93beea",
   "metadata": {},
   "source": [
    "### merge origin and dest weather df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eab00ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14600, 3),\n",
       "       fl_date origin_city_name origin_city_condn\n",
       " 0  2018-01-01        Tampa, FL        low_rainny\n",
       " 1  2018-01-01  New Orleans, LA           cloundy\n",
       " 2  2018-01-01  New Orleans, LA           cloundy\n",
       " 3  2018-01-01  New Orleans, LA           cloundy\n",
       " 4  2018-01-01  New Orleans, LA           cloundy)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_wth = pd.read_csv('origin_weather_merged.csv')\n",
    "dest_wth = pd.read_csv('dest_weather_merged.csv')\n",
    "origin_wth.drop(columns='Unnamed: 0', inplace=True)\n",
    "dest_wth.drop(columns='Unnamed: 0', inplace=True)\n",
    "origin_wth.shape, origin_wth.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b65f8f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14600, 3),\n",
       "       fl_date dest_city_name dest_city_condn\n",
       " 0  2018-01-01     Albany, NY           sunny\n",
       " 1  2018-01-01    Houston, TX           sunny\n",
       " 2  2018-01-01    Orlando, FL      low_rainny\n",
       " 3  2018-01-01    Oakland, CA           sunny\n",
       " 4  2018-01-01  St. Louis, MO           sunny)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_wth.shape, dest_wth.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bbaf67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>origin_city_condn</th>\n",
       "      <th>dest_city_name</th>\n",
       "      <th>dest_city_condn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>low_rainny</td>\n",
       "      <td>Albany, NY</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>low_rainny</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>low_rainny</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>low_rainny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>low_rainny</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>low_rainny</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291995</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>sunny</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291996</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>sunny</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>low_snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291997</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>sunny</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291998</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>sunny</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291999</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>sunny</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fl_date origin_city_name origin_city_condn   dest_city_name  \\\n",
       "0       2018-01-01        Tampa, FL        low_rainny       Albany, NY   \n",
       "1       2018-01-01        Tampa, FL        low_rainny      Houston, TX   \n",
       "2       2018-01-01        Tampa, FL        low_rainny      Orlando, FL   \n",
       "3       2018-01-01        Tampa, FL        low_rainny      Oakland, CA   \n",
       "4       2018-01-01        Tampa, FL        low_rainny    St. Louis, MO   \n",
       "...            ...              ...               ...              ...   \n",
       "291995  2019-12-31   Long Beach, CA             sunny  Kansas City, MO   \n",
       "291996  2019-12-31   Long Beach, CA             sunny      Chicago, IL   \n",
       "291997  2019-12-31   Long Beach, CA             sunny  New Orleans, LA   \n",
       "291998  2019-12-31   Long Beach, CA             sunny        Tampa, FL   \n",
       "291999  2019-12-31   Long Beach, CA             sunny     San Jose, CA   \n",
       "\n",
       "       dest_city_condn  \n",
       "0                sunny  \n",
       "1                sunny  \n",
       "2           low_rainny  \n",
       "3                sunny  \n",
       "4                sunny  \n",
       "...                ...  \n",
       "291995           sunny  \n",
       "291996        low_snow  \n",
       "291997           sunny  \n",
       "291998           sunny  \n",
       "291999           sunny  \n",
       "\n",
       "[292000 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#when tables have duplicate values in columns, merge them in pandas will be .dot() product of two tables\n",
    "pd.merge(origin_wth, dest_wth, how=\"left\", on=[\"fl_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f32fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14600, 3),\n",
       "       fl_date origin_city_name dest_city_name\n",
       " 0  2018-01-01        Tampa, FL     Albany, NY\n",
       " 1  2018-01-01  New Orleans, LA    Houston, TX\n",
       " 2  2018-01-01  New Orleans, LA    Orlando, FL\n",
       " 3  2018-01-01  New Orleans, LA    Oakland, CA\n",
       " 4  2018-01-01  New Orleans, LA  St. Louis, MO)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes = flights[['fl_date','origin_city_name', 'dest_city_name']]\n",
    "routes.shape, routes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d7dfb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_merged = pd.merge(routes, origin_wth.drop_duplicates(), how=\"left\", on=[\"fl_date\", \"origin_city_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6713ca01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fl_date              0\n",
       "origin_city_name     0\n",
       "dest_city_name       0\n",
       "origin_city_condn    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a14deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dest_weather = pd.merge(first_merged, dest_wth.drop_duplicates(), how=\"left\", on=[\"fl_date\", \"dest_city_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5245937c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14600, 5),\n",
       "       fl_date origin_city_name dest_city_name origin_city_condn  \\\n",
       " 0  2018-01-01        Tampa, FL     Albany, NY        low_rainny   \n",
       " 1  2018-01-01  New Orleans, LA    Houston, TX           cloundy   \n",
       " 2  2018-01-01  New Orleans, LA    Orlando, FL           cloundy   \n",
       " 3  2018-01-01  New Orleans, LA    Oakland, CA           cloundy   \n",
       " 4  2018-01-01  New Orleans, LA  St. Louis, MO           cloundy   \n",
       " \n",
       "   dest_city_condn  \n",
       " 0           sunny  \n",
       " 1           sunny  \n",
       " 2      low_rainny  \n",
       " 3           sunny  \n",
       " 4           sunny  )"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_dest_weather.shape, origin_dest_weather.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "619a7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dest_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c6b7fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fl_date</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>dest_city_name</th>\n",
       "      <th>origin_city_condn</th>\n",
       "      <th>dest_city_condn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Albany, NY</td>\n",
       "      <td>low_rainny</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>cloundy</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>cloundy</td>\n",
       "      <td>low_rainny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>cloundy</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>cloundy</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14595</th>\n",
       "      <td>14595</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>cloundy</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14596</th>\n",
       "      <td>14596</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>cloundy</td>\n",
       "      <td>low_snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14597</th>\n",
       "      <td>14597</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>cloundy</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14598</th>\n",
       "      <td>14598</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>cloundy</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14599</th>\n",
       "      <td>14599</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>sunny</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14600 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     fl_date origin_city_name   dest_city_name  \\\n",
       "0               0  2018-01-01        Tampa, FL       Albany, NY   \n",
       "1               1  2018-01-01  New Orleans, LA      Houston, TX   \n",
       "2               2  2018-01-01  New Orleans, LA      Orlando, FL   \n",
       "3               3  2018-01-01  New Orleans, LA      Oakland, CA   \n",
       "4               4  2018-01-01  New Orleans, LA    St. Louis, MO   \n",
       "...           ...         ...              ...              ...   \n",
       "14595       14595  2019-12-31     New York, NY  Kansas City, MO   \n",
       "14596       14596  2019-12-31     New York, NY      Chicago, IL   \n",
       "14597       14597  2019-12-31     New York, NY  New Orleans, LA   \n",
       "14598       14598  2019-12-31     New York, NY        Tampa, FL   \n",
       "14599       14599  2019-12-31   Long Beach, CA     San Jose, CA   \n",
       "\n",
       "      origin_city_condn dest_city_condn  \n",
       "0            low_rainny           sunny  \n",
       "1               cloundy           sunny  \n",
       "2               cloundy      low_rainny  \n",
       "3               cloundy           sunny  \n",
       "4               cloundy           sunny  \n",
       "...                 ...             ...  \n",
       "14595           cloundy           sunny  \n",
       "14596           cloundy        low_snow  \n",
       "14597           cloundy           sunny  \n",
       "14598           cloundy           sunny  \n",
       "14599             sunny           sunny  \n",
       "\n",
       "[14600 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('final_origin_dest_weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c09bb2f",
   "metadata": {},
   "source": [
    "## traffic flight cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "03928466",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_traff = pd.read_csv('data/flight_traffic_20182019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "63dbe33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>dest_city_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberdeen, SD</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>4291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adak Island, AK</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aguadilla, PR</td>\n",
       "      <td>Fort Lauderdale, FL</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aguadilla, PR</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  origin_city_name         dest_city_name  count\n",
       "0     Aberdeen, SD        Minneapolis, MN   1492\n",
       "1      Abilene, TX  Dallas/Fort Worth, TX   4291\n",
       "2  Adak Island, AK          Anchorage, AK    207\n",
       "3    Aguadilla, PR    Fort Lauderdale, FL   1258\n",
       "4    Aguadilla, PR             Newark, NJ    674"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_traff.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "38b4a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_data = flights[['fl_date', 'origin_city_name', 'dest_city_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "af8914da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>dest_city_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Albany, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>Houston, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>Orlando, FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>Oakland, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date origin_city_name dest_city_name\n",
       "0  2018-01-01        Tampa, FL     Albany, NY\n",
       "1  2018-01-01  New Orleans, LA    Houston, TX\n",
       "2  2018-01-01  New Orleans, LA    Orlando, FL\n",
       "3  2018-01-01  New Orleans, LA    Oakland, CA\n",
       "4  2018-01-01  New Orleans, LA  St. Louis, MO"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c52ef1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "traff_merged = pd.merge(fl_data, fl_traff, how=\"left\", on=[\"origin_city_name\",\"dest_city_name\"])a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ef5b7db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14600, 4),\n",
       "       fl_date origin_city_name dest_city_name  count\n",
       " 0  2018-01-01        Tampa, FL     Albany, NY    741\n",
       " 1  2018-01-01  New Orleans, LA    Houston, TX  12826\n",
       " 2  2018-01-01  New Orleans, LA    Orlando, FL   3889\n",
       " 3  2018-01-01  New Orleans, LA    Oakland, CA    710\n",
       " 4  2018-01-01  New Orleans, LA  St. Louis, MO   1466)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traff_merged.shape, traff_merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d2c5ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "traff_merged.to_csv('data/traff_flights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84fccde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20cfa32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb31bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
